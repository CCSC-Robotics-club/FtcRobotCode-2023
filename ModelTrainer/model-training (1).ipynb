{"cells":[{"cell_type":"code","metadata":{"id":"47A882CDAAA940F2A0378BD64E7AF38C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow.compat.v1 as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","outputs":[],"execution_count":12},{"cell_type":"code","metadata":{"id":"7F0B9831AF5846E7949E25AA6BF5AAAB","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import os\nvisualMark1 = []\nvisualMark2 = []\nvisualMark3 = []\nfor imageName in os.listdir(r'1'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('1/'+imageName))\n    print(\"loaded asset\", imageName)\nfor imageName in os.listdir(r'2'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('2/'+imageName))\n    print(\"loaded asset\", imageName)\nfor imageName in os.listdir(r'3'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('3/'+imageName))\n    print(\"loaded asset\", imageName)","outputs":[{"output_type":"stream","name":"stdout","text":"loaded asset WIN_20230328_17_42_00_Pro.jpg\nloaded asset WIN_20230328_17_42_03_Pro.jpg\nloaded asset WIN_20230328_17_42_04_Pro.jpg\nloaded asset WIN_20230328_17_42_07_Pro.jpg\nloaded asset WIN_20230328_17_42_08_Pro.jpg\nloaded asset WIN_20230328_17_42_13_Pro.jpg\nloaded asset WIN_20230328_17_42_19_Pro (2).jpg\nloaded asset WIN_20230328_17_42_19_Pro.jpg\nloaded asset WIN_20230328_17_42_37_Pro.jpg\nloaded asset WIN_20230328_17_42_39_Pro.jpg\nloaded asset WIN_20230328_17_42_47_Pro.jpg\nloaded asset WIN_20230328_17_42_50_Pro.jpg\nloaded asset WIN_20230328_17_42_52_Pro.jpg\nloaded asset WIN_20230328_17_42_55_Pro.jpg\nloaded asset WIN_20230328_17_42_58_Pro.jpg\nloaded asset WIN_20230328_17_43_01_Pro.jpg\nloaded asset WIN_20230328_17_43_03_Pro.jpg\nloaded asset WIN_20230328_17_43_08_Pro.jpg\nloaded asset WIN_20230328_17_44_39_Pro.jpg\nloaded asset WIN_20230328_17_44_42_Pro.jpg\nloaded asset WIN_20230328_17_44_44_Pro.jpg\nloaded asset WIN_20230328_17_44_48_Pro.jpg\nloaded asset WIN_20230328_17_44_51_Pro.jpg\nloaded asset WIN_20230328_17_44_53_Pro.jpg\nloaded asset WIN_20230328_17_44_55_Pro.jpg\nloaded asset WIN_20230328_17_44_57_Pro.jpg\nloaded asset WIN_20230328_17_45_01_Pro.jpg\nloaded asset WIN_20230328_17_45_03_Pro.jpg\nloaded asset WIN_20230328_17_45_06_Pro.jpg\nloaded asset WIN_20230328_17_46_00_Pro.jpg\nloaded asset WIN_20230328_17_46_02_Pro.jpg\nloaded asset WIN_20230328_17_46_06_Pro.jpg\nloaded asset WIN_20230328_17_46_10_Pro.jpg\nloaded asset WIN_20230328_17_46_12_Pro.jpg\nloaded asset WIN_20230328_17_46_13_Pro.jpg\nloaded asset WIN_20230328_17_46_18_Pro.jpg\nloaded asset WIN_20230328_17_43_53_Pro.jpg\nloaded asset WIN_20230328_17_43_54_Pro.jpg\nloaded asset WIN_20230328_17_43_57_Pro.jpg\nloaded asset WIN_20230328_17_44_00_Pro.jpg\nloaded asset WIN_20230328_17_44_01_Pro.jpg\nloaded asset WIN_20230328_17_44_05_Pro.jpg\nloaded asset WIN_20230328_17_44_06_Pro.jpg\nloaded asset WIN_20230328_17_44_10_Pro.jpg\nloaded asset WIN_20230328_17_44_11_Pro.jpg\nloaded asset WIN_20230328_17_44_13_Pro (2).jpg\nloaded asset WIN_20230328_17_44_13_Pro.jpg\nloaded asset WIN_20230328_17_44_17_Pro.jpg\nloaded asset WIN_20230328_17_44_18_Pro.jpg\nloaded asset WIN_20230328_17_44_21_Pro.jpg\nloaded asset WIN_20230328_17_44_22_Pro.jpg\nloaded asset WIN_20230328_17_44_24_Pro.jpg\nloaded asset WIN_20230328_17_44_28_Pro.jpg\nloaded asset WIN_20230328_17_44_30_Pro.jpg\n"}],"execution_count":6},{"cell_type":"code","metadata":{"id":"A6F34E846FF543E2848B699016CF39FA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"batch_size = 15\nimg_height = 720\nimg_width = 1280\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'keras.api._v1.keras.utils' has no attribute 'image_dataset_from_directory'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1297397227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m_getattr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \"\"\"\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m# Placeholder for Google-internal contrib error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v1.keras.utils' has no attribute 'image_dataset_from_directory'"]}],"execution_count":8},{"cell_type":"code","metadata":{"id":"3B5784E8644D4D5888E63182535C0EFF","notebookId":"63e72939b5fa5410338747d2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# process and cut the pictures\nfrom PIL import Image\nimport os\n\npath = '/home/mw/'\nfor i in range(1,4):\n    for rawImage in os.listdir(path + str(i) + \"/\"):\n        img = Image.open(path + str(i) + \"/\" + rawImage) # read image from file system\n        img = img.rotate(180) # rotate it 180 degrees\n        box = (400, 360, 760, 720) # the region that the signal sleeves will be seen\n        img = img.crop(box) # cut the region down, into a 360 by 360 image\n        img.show()\n        img.save(path + str(i) + \"/\" + rawImage) # replace the original picture","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C423D90>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk6eao4.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D10>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk6cmwz.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C3CC150>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk64whj.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490FD0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk6g8bf.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490190>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk75k0b.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490FD0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk7dvym.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C3CC150>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk7scjm.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C423650>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk7rhid.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D4901D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk8ra9h.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490190>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk81vff.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D4901D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk8bk41.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490190>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk9jtfm.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D4901D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk9h4bz.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C423D90>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gk9l9c.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C423650>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkauziv.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkabtsc.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490F90>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkbdx3t.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D4829D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkby2r3.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkbtvat.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D4829D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkby3xc.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkc8qwg.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkc248l.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C423990>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkcq7nh.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkc90qq.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C3CC150>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkd6vqf.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C423650>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkdt3zq.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490F90>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkd3erz.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D4829D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkdzpfi.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkedg9k.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F10>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkfqkll.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C3CC150>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkf5u9h.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C423990>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkfp4eo.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D4829D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkg6bw1.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F10>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkga5xo.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkg1y8i.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C3CC150>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkh1kmj.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkhjryw.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC55C423D90>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkiw5yf.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkiu36y.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D4829D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkjx497.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490FD0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkjnjss.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F10>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkjnvpe.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490FD0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkjc4c5.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D490190>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkk99kf.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkkmoh7.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkkznph.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gklvq7g.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkl3m9m.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gklraxs.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkmkfsy.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkmswk9.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkn6gah.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gknze4v.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FC40D482F50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs8gkoybyf.png\">"},"metadata":{}}],"execution_count":2},{"cell_type":"code","metadata":{"id":"18BDDC139D82410F9777D9FF313738DE","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import os\ndatas = []\nlabels = []\nfpaths = []\nfor imageName in os.listdir(r'/home/mw/1/'):\n    fpath = '/home/mw/1/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/1/'+imageName)) / 255.0\n    label = 0\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\nfor imageName in os.listdir(r'/home/mw/2/'):\n    fpath = '/home/mw/2/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/2/'+imageName)) / 255.0\n    label = 1\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\nfor imageName in os.listdir(r'/home/mw/3/'):\n    fpath = '/home/mw/3/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/3/'+imageName)) / 255.0\n    label = 2\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\n    \ndatas = np.array(datas)\nlabels = np.array(labels)\n\nnum_classes = 3","outputs":[],"execution_count":13},{"cell_type":"code","metadata":{"id":"8548BBC73C284CFB82E7AEB1CDAE499E","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"tf.disable_eager_execution()\n# 定义Placeholder，存放输入和标签\ndatas_placeholder = tf.placeholder(tf.float32, [None, 360, 360, 3])\nlabels_placeholder = tf.placeholder(tf.int32, [None])\n\n# 存放DropOut参数的容器，训练时为0.25，测试时为0\ndropout_placeholdr = tf.placeholder(tf.float32)\n\n# 定义卷积层, 20个卷积核, 卷积核大小为5，用Relu激活\nconv0 = tf.layers.conv2d(datas_placeholder, 20, 5, activation=tf.nn.relu)\n# 定义max-pooling层，pooling窗口为2x2，步长为2x2\npool0 = tf.layers.max_pooling2d(conv0, [2, 2], [2, 2])\n\n# 定义卷积层, 40个卷积核, 卷积核大小为4，用Relu激活\nconv1 = tf.layers.conv2d(pool0, 40, 4, activation=tf.nn.relu)\n# 定义max-pooling层，pooling窗口为2x2，步长为2x2\npool1 = tf.layers.max_pooling2d(conv1, [2, 2], [2, 2])\n\n# 将3维特征转换为1维向量\nflatten = tf.layers.flatten(pool1)\n\n# 全连接层，转换为长度为100的特征向量\nfc = tf.layers.dense(flatten, 400, activation=tf.nn.relu)\n\n# 加上DropOut，防止过拟合\ndropout_fc = tf.layers.dropout(fc, dropout_placeholdr)\n\n# 未激活的输出层\nlogits = tf.layers.dense(dropout_fc, num_classes)\n\npredicted_labels = tf.arg_max(logits, 1)\n\n\n# 利用交叉熵定义损失\nlosses = tf.nn.softmax_cross_entropy_with_logits(\n    labels=tf.one_hot(labels_placeholder, num_classes),\n    logits=logits\n)\n# 平均损失\nmean_loss = tf.reduce_mean(losses)\n\n# 定义优化器，指定要优化的损失函数\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(losses)","outputs":[],"execution_count":14},{"cell_type":"code","metadata":{"id":"5BD164ED92E442AA9791C478114F05C2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"saver = tf.train.Saver()\ntrain = True\nmodel_path = \"/home/mw/models/signal-sleeves-identifier.model\"\nwith tf.Session() as sess:\n    if train:\n        print(\"训练模式\")\n        # 如果是训练，初始化参数\n        sess.run(tf.global_variables_initializer())\n        # 定义输入和Label以填充容器，训练时dropout为0.25\n        train_feed_dict = {\n            datas_placeholder: datas,\n            labels_placeholder: labels,\n            dropout_placeholdr: 0.25\n        }\n        for step in range(2):\n            _, mean_loss_val = sess.run([optimizer, mean_loss], feed_dict=train_feed_dict)\n\n            print(\"step = {}\\tmean loss = {}\".format(step, mean_loss_val))\n        tf.compat.v1.saved_model.simple_save( #保存模型\n            sess, model_path, \n            inputs = {\"myInput\": datas_placeholder},\n            outputs = {\"myOutput\" :labels_placeholder}\n        )\n        print(\"训练结束，保存模型到{}\".format(model_path))\n    \n    \n    else:\n        print(\"测试模式\")\n        # 如果是测试，载入参数\n        saver.restore(sess, model_path)\n        print(\"从{}载入模型\".format(model_path))\n        # label和名称的对照关系\n        label_name_dict = {\n            0: \"标识1\",\n            1: \"标识2\",\n            2: \"标识3\"\n        }\n        # 定义输入和Label以填充容器，测试时dropout为0\n        test_feed_dict = {\n            datas_placeholder: datas,\n            labels_placeholder: labels,\n            dropout_placeholdr: 0\n        }\n        predicted_labels_val = sess.run(predicted_labels, feed_dict=test_feed_dict)\n        # 真实label与模型预测label\n        for fpath, real_label, predicted_label in zip(fpaths, labels, predicted_labels_val):\n            # 将label id转换为label名\n            real_label_name = label_name_dict[real_label]\n            predicted_label_name = label_name_dict[predicted_label]\n            print(\"{}\\t{} => {}\".format(fpath, real_label_name, predicted_label_name))","outputs":[{"output_type":"stream","name":"stdout","text":"训练模式\nstep = 0\tmean loss = 1.0979759693145752\nstep = 1\tmean loss = 827.7444458007812\nINFO:tensorflow:Assets added to graph.\n"},{"output_type":"stream","name":"stderr","text":"INFO:tensorflow:Assets added to graph.\n"},{"output_type":"stream","name":"stdout","text":"INFO:tensorflow:No assets to write.\n"},{"output_type":"stream","name":"stderr","text":"INFO:tensorflow:No assets to write.\n"},{"output_type":"stream","name":"stdout","text":"INFO:tensorflow:SavedModel written to: /home/mw/models/signal-sleeves-identifier.pb/saved_model.pb\n"},{"output_type":"stream","name":"stderr","text":"INFO:tensorflow:SavedModel written to: /home/mw/models/signal-sleeves-identifier.pb/saved_model.pb\n"},{"output_type":"stream","name":"stdout","text":"训练结束，保存模型到/home/mw/models/signal-sleeves-identifier.pb\n"}],"execution_count":23},{"cell_type":"code","metadata":{"id":"0B7E502647AB42D38B001EFED1D88812","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import tensorflow as tf\nfrom tensorflow.python.platform import gfile\n\n# first, convert the model into pbtxt file\nwith gfile.FastGFile(model_path + \"/saved_model.pb\") as f:\n  graph_def = tf.compat.v1.GraphDef()\n  graph_def.ParseFromString(f.read())\n  tf.import_graph_def(graph_def, name='')\n  tf.train.write_graph(graph_def, \"./\", \"signal_sleeves.pbtxt\", as_text=True)\n\n# Convert the model\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"/home/mw/models/\") # path to the SavedModel directory\n\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)","outputs":[{"output_type":"error","ename":"UnicodeDecodeError","evalue":"'utf-8' codec can't decode bytes in position 3-4: invalid continuation byte","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/77386045.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/saved_model.pb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"signal_sleeves.pbtxt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   @deprecation.deprecated_args(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_prepare_value\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_str_any\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \"\"\"\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_str\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'compat.as_text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_text\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected binary or unicode string, got %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 3-4: invalid continuation byte"]}],"execution_count":30},{"cell_type":"code","metadata":{"id":"066B277589E144488A65C852FAB8A773","notebookId":"63e72939b5fa5410338747d2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"os.system(\"tflite_convert --saved_model_dir=./signal-sleeves-identifier.pb.data-00000-of-00001 --output_file=./signal_sleeves.tflite\")","outputs":[{"output_type":"stream","name":"stderr","text":"Traceback (most recent call last):\n  File \"/opt/conda/bin/tflite_convert\", line 8, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 697, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 680, in run_main\n    _convert_tf2_model(tflite_flags)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 284, in _convert_tf2_model\n    tags=_parse_set(flags.saved_model_tag_set))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 1348, in from_saved_model\n    saved_model = _load(saved_model_dir, tags)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 864, in load\n    result = load_internal(export_dir, tags, options)[\"root\"]\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 878, in load_internal\n    loader_impl.parse_saved_model_with_debug_info(export_dir))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 60, in parse_saved_model_with_debug_info\n    saved_model = _parse_saved_model(export_dir)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 121, in parse_saved_model\n    constants.SAVED_MODEL_FILENAME_PB))\nOSError: SavedModel file does not exist at: ./signal-sleeves-identifier.pb.data-00000-of-00001/{saved_model.pbtxt|saved_model.pb}\n"},{"output_type":"execute_result","data":{"text/plain":"256"},"metadata":{}}],"execution_count":9}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}
{"cells":[{"cell_type":"code","metadata":{"id":"47A882CDAAA940F2A0378BD64E7AF38C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow.compat.v1 as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","outputs":[],"execution_count":34},{"cell_type":"code","metadata":{"id":"7F0B9831AF5846E7949E25AA6BF5AAAB","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import os\nvisualMark1 = []\nvisualMark2 = []\nvisualMark3 = []\nfor imageName in os.listdir(r'1'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('1/'+imageName))\n    print(\"loaded asset\", imageName)\nfor imageName in os.listdir(r'2'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('2/'+imageName))\n    print(\"loaded asset\", imageName)\nfor imageName in os.listdir(r'3'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('3/'+imageName))\n    print(\"loaded asset\", imageName)","outputs":[{"output_type":"stream","name":"stdout","text":"loaded asset WIN_20230328_17_42_00_Pro.jpg\nloaded asset WIN_20230328_17_42_03_Pro.jpg\nloaded asset WIN_20230328_17_42_04_Pro.jpg\nloaded asset WIN_20230328_17_42_07_Pro.jpg\nloaded asset WIN_20230328_17_42_08_Pro.jpg\nloaded asset WIN_20230328_17_42_13_Pro.jpg\nloaded asset WIN_20230328_17_42_19_Pro (2).jpg\nloaded asset WIN_20230328_17_42_19_Pro.jpg\nloaded asset WIN_20230328_17_42_37_Pro.jpg\nloaded asset WIN_20230328_17_42_39_Pro.jpg\nloaded asset WIN_20230328_17_42_47_Pro.jpg\nloaded asset WIN_20230328_17_42_50_Pro.jpg\nloaded asset WIN_20230328_17_42_52_Pro.jpg\nloaded asset WIN_20230328_17_42_55_Pro.jpg\nloaded asset WIN_20230328_17_42_58_Pro.jpg\nloaded asset WIN_20230328_17_43_01_Pro.jpg\nloaded asset WIN_20230328_17_43_03_Pro.jpg\nloaded asset WIN_20230328_17_43_08_Pro.jpg\nloaded asset WIN_20230328_17_44_39_Pro.jpg\nloaded asset WIN_20230328_17_44_42_Pro.jpg\nloaded asset WIN_20230328_17_44_44_Pro.jpg\nloaded asset WIN_20230328_17_44_48_Pro.jpg\nloaded asset WIN_20230328_17_44_51_Pro.jpg\nloaded asset WIN_20230328_17_44_53_Pro.jpg\nloaded asset WIN_20230328_17_44_55_Pro.jpg\nloaded asset WIN_20230328_17_44_57_Pro.jpg\nloaded asset WIN_20230328_17_45_01_Pro.jpg\nloaded asset WIN_20230328_17_45_03_Pro.jpg\nloaded asset WIN_20230328_17_45_06_Pro.jpg\nloaded asset WIN_20230328_17_46_00_Pro.jpg\nloaded asset WIN_20230328_17_46_02_Pro.jpg\nloaded asset WIN_20230328_17_46_06_Pro.jpg\nloaded asset WIN_20230328_17_46_10_Pro.jpg\nloaded asset WIN_20230328_17_46_12_Pro.jpg\nloaded asset WIN_20230328_17_46_13_Pro.jpg\nloaded asset WIN_20230328_17_46_18_Pro.jpg\nloaded asset WIN_20230328_17_43_53_Pro.jpg\nloaded asset WIN_20230328_17_43_54_Pro.jpg\nloaded asset WIN_20230328_17_43_57_Pro.jpg\nloaded asset WIN_20230328_17_44_00_Pro.jpg\nloaded asset WIN_20230328_17_44_01_Pro.jpg\nloaded asset WIN_20230328_17_44_05_Pro.jpg\nloaded asset WIN_20230328_17_44_06_Pro.jpg\nloaded asset WIN_20230328_17_44_10_Pro.jpg\nloaded asset WIN_20230328_17_44_11_Pro.jpg\nloaded asset WIN_20230328_17_44_13_Pro (2).jpg\nloaded asset WIN_20230328_17_44_13_Pro.jpg\nloaded asset WIN_20230328_17_44_17_Pro.jpg\nloaded asset WIN_20230328_17_44_18_Pro.jpg\nloaded asset WIN_20230328_17_44_21_Pro.jpg\nloaded asset WIN_20230328_17_44_22_Pro.jpg\nloaded asset WIN_20230328_17_44_24_Pro.jpg\nloaded asset WIN_20230328_17_44_28_Pro.jpg\nloaded asset WIN_20230328_17_44_30_Pro.jpg\n"}],"execution_count":6},{"cell_type":"code","metadata":{"id":"A6F34E846FF543E2848B699016CF39FA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"batch_size = 15\nimg_height = 720\nimg_width = 1280\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'keras.api._v1.keras.utils' has no attribute 'image_dataset_from_directory'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1297397227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m_getattr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \"\"\"\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m# Placeholder for Google-internal contrib error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v1.keras.utils' has no attribute 'image_dataset_from_directory'"]}],"execution_count":8},{"cell_type":"code","metadata":{"id":"3B5784E8644D4D5888E63182535C0EFF","notebookId":"63e72939b5fa5410338747d2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# process and cut the pictures\nfrom PIL import Image\nimport os\n\npath = '/home/mw/'\nfor i in range(1,4):\n    for rawImage in os.listdir(path + str(i) + \"/\"):\n        img = Image.open(path + str(i) + \"/\" + rawImage) # read image from file system\n        img = img.rotate(180) # rotate it 180 degrees\n        box = (400, 360, 760, 720) # the region that the signal sleeves will be seen\n        img = img.crop(box) # cut the region down, into a 360 by 360 image\n        img.show()\n        img.save(path + str(i) + \"/\" + rawImage) # replace the original picture","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E774D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w4e7cn.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F87B10>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w460ok.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F87350>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w4d9h0.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w4hpxz.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E909D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w4u0uw.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w42ujh.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w479px.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90950>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w4v1c9.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w4h0z9.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5n32t.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E909D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5kb2l.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5wau1.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5sr80.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90950>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5tuyl.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5yuy.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5dyyg.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E909D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5elgj.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5yc63.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w5gw3t.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90950>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w6j1hb.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w6l69o.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w6xq1e.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90810>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w6lcau.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w6fvu1.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w6br8e.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90950>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w66w95.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w6u417.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w6na3i.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90810>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w755bg.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w7676g.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w7i3rz.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90950>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w7c7fe.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w7yxu0.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w7sz2y.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90810>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w7yw87.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w7ng4o.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w7pxch.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90950>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w89km8.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w8k0g5.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w852i7.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E909D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w86cub.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w8usnk.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w8ponv.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E90950>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w8gt4b.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w8z0hh.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w8ul7h.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E909D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w8gb41.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w9gh01.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E909D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w9kct4.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w9s9iw.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F002D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w9bipt.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6E909D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w97c9q.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F1F310>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w9ybti.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FECC6F00C50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs87w97awm.png\">"},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"resize() missing 1 required positional argument: 'size'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3889261412.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrawImage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# replace the original picture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mnew_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: resize() missing 1 required positional argument: 'size'"]}],"execution_count":19},{"cell_type":"code","metadata":{"id":"18BDDC139D82410F9777D9FF313738DE","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import os\ndatas = []\nlabels = []\nfpaths = []\nfor imageName in os.listdir(r'/home/mw/1/'):\n    fpath = '/home/mw/1/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/1/'+imageName)) / 255.0\n    label = 0\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\nfor imageName in os.listdir(r'/home/mw/2/'):\n    fpath = '/home/mw/2/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/2/'+imageName)) / 255.0\n    label = 1\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\nfor imageName in os.listdir(r'/home/mw/3/'):\n    fpath = '/home/mw/3/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/3/'+imageName)) / 255.0\n    label = 2\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\n    \ndatas = np.array(datas)\nlabels = np.array(labels)\n\nnum_classes = 3","outputs":[],"execution_count":35},{"cell_type":"code","metadata":{"id":"8548BBC73C284CFB82E7AEB1CDAE499E","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"tf.disable_eager_execution()\n# 定义Placeholder，存放输入和标签\ndatas_placeholder = tf.placeholder(tf.float32, [None, 360, 360, 3])\nlabels_placeholder = tf.placeholder(tf.int32, [None])\n\n# 存放DropOut参数的容器，训练时为0.25，测试时为0\ndropout_placeholdr = tf.placeholder(tf.float32)\n\n# 定义卷积层, 20个卷积核, 卷积核大小为5，用Relu激活\nconv0 = tf.layers.conv2d(datas_placeholder, 20, 5, activation=tf.nn.relu)\n# 定义max-pooling层，pooling窗口为2x2，步长为2x2\npool0 = tf.layers.max_pooling2d(conv0, [2, 2], [2, 2])\n\n# 定义卷积层, 40个卷积核, 卷积核大小为4，用Relu激活\nconv1 = tf.layers.conv2d(pool0, 40, 4, activation=tf.nn.relu)\n# 定义max-pooling层，pooling窗口为2x2，步长为2x2\npool1 = tf.layers.max_pooling2d(conv1, [2, 2], [2, 2])\n\n# 将3维特征转换为1维向量\nflatten = tf.layers.flatten(pool1)\n\n# 全连接层，转换为长度为100的特征向量\nfc = tf.layers.dense(flatten, 400, activation=tf.nn.relu)\n\n# 加上DropOut，防止过拟合\ndropout_fc = tf.layers.dropout(fc, dropout_placeholdr)\n\n# 未激活的输出层\nlogits = tf.layers.dense(dropout_fc, num_classes)\n\npredicted_labels = tf.arg_max(logits, 1)\n\n\n# 利用交叉熵定义损失\nlosses = tf.nn.softmax_cross_entropy_with_logits(\n    labels=tf.one_hot(labels_placeholder, num_classes),\n    logits=logits\n)\n# 平均损失\nmean_loss = tf.reduce_mean(losses)\n\n# 定义优化器，指定要优化的损失函数\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(losses)","outputs":[],"execution_count":36},{"cell_type":"code","metadata":{"id":"5BD164ED92E442AA9791C478114F05C2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"saver = tf.train.Saver()\ntrain = True\nmodel_path = \"/home/mw/models/signal-sleeves-identifier.model\"\nwith tf.Session() as sess:\n    if train:\n        print(\"训练模式\")\n        # 如果是训练，初始化参数\n        sess.run(tf.global_variables_initializer())\n        # 定义输入和Label以填充容器，训练时dropout为0.25\n        train_feed_dict = {\n            datas_placeholder: datas,\n            labels_placeholder: labels,\n            dropout_placeholdr: 0.25\n        }\n        for step in range(20):\n            _, mean_loss_val = sess.run([optimizer, mean_loss], feed_dict=train_feed_dict)\n\n            print(\"step = {}\\tmean loss = {}\".format(step, mean_loss_val))\n        saver.save(sess, model_path)\n        print(\"训练结束，保存模型到{}\".format(model_path))\n    else:\n        print(\"测试模式\")\n        # 如果是测试，载入参数\n        saver.restore(sess, model_path)\n        print(\"从{}载入模型\".format(model_path))\n        # label和名称的对照关系\n        label_name_dict = {\n            0: \"标识1\",\n            1: \"标识2\",\n            2: \"标识3\"\n        }\n        # 定义输入和Label以填充容器，测试时dropout为0\n        test_feed_dict = {\n            datas_placeholder: datas,\n            labels_placeholder: labels,\n            dropout_placeholdr: 0\n        }\n        predicted_labels_val = sess.run(predicted_labels, feed_dict=test_feed_dict)\n        # 真实label与模型预测label\n        for fpath, real_label, predicted_label in zip(fpaths, labels, predicted_labels_val):\n            # 将label id转换为label名\n            real_label_name = label_name_dict[real_label]\n            predicted_label_name = label_name_dict[predicted_label]\n            print(\"{}\\t{} => {}\".format(fpath, real_label_name, predicted_label_name))","outputs":[{"output_type":"stream","name":"stdout","text":"训练模式\nstep = 0\tmean loss = 1.1070829629898071\nstep = 1\tmean loss = 558.313720703125\nstep = 2\tmean loss = 207.29287719726562\nstep = 3\tmean loss = 103.57177734375\nstep = 4\tmean loss = 13.738978385925293\nstep = 5\tmean loss = 4.244316101074219\nstep = 6\tmean loss = 3.358457326889038\nstep = 7\tmean loss = 1.8054696321487427\nstep = 8\tmean loss = 1.10508394241333\nstep = 9\tmean loss = 1.0987297296524048\nstep = 10\tmean loss = 1.0986939668655396\nstep = 11\tmean loss = 1.0986692905426025\nstep = 12\tmean loss = 1.09866201877594\nstep = 13\tmean loss = 1.0986684560775757\nstep = 14\tmean loss = 1.0986783504486084\nstep = 15\tmean loss = 1.0986965894699097\nstep = 16\tmean loss = 1.0987169742584229\nstep = 17\tmean loss = 1.0987375974655151\nstep = 18\tmean loss = 1.098758578300476\nstep = 19\tmean loss = 1.09877610206604\n训练结束，保存模型到/home/mw/models/signal-sleeves-identifier.model\n"}],"execution_count":38},{"cell_type":"code","metadata":{"id":"0B7E502647AB42D38B001EFED1D88812","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import tensorflow as tf\n\n# Convert the model\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"/home/mw/models/\") # path to the SavedModel directory\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)","outputs":[{"output_type":"stream","name":"stderr","text":"WARNING:absl:Invoking the TF1 implementation of TFLiteConverter because eager is disabled. Consider enabling eager.\n"},{"output_type":"error","ename":"OSError","evalue":"SavedModel file does not exist at: /home/mw/models/signal-sleeves-identifier.model.data-00000-of-00001/{saved_model.pbtxt|saved_model.pb}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/2357844432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Convert the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/mw/models/signal-sleeves-identifier.model.data-00000-of-00001\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# path to the SavedModel directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[1;32m   1338\u001b[0m                       \"because eager is disabled. Consider enabling eager.\")\n\u001b[1;32m   1339\u001b[0m       return TFLiteConverter.from_saved_model(\n\u001b[0;32m-> 1340\u001b[0;31m           saved_model_dir, signature_key=signature_key, tag_set=tags)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;31m# Ensures any graphs created in Eager mode are able to run. This is required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[1;32m   2265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m     saved_model_converter = TFLiteSavedModelConverter(saved_model_dir, tag_set,\n\u001b[0;32m-> 2267\u001b[0;31m                                                       [signature_key])\n\u001b[0m\u001b[1;32m   2268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msaved_model_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_converter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, saved_model_dir, saved_model_tags, saved_model_exported_names, experimental_debug_info_func)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     result = _freeze_saved_model(self.saved_model_dir, None, None, None,\n\u001b[0;32m-> 1744\u001b[0;31m                                  self._saved_model_tags, signature_key)\n\u001b[0m\u001b[1;32m   1745\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mfreeze_saved_model\u001b[0;34m(saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[1;32m    189\u001b[0m   \"\"\"\n\u001b[1;32m    190\u001b[0m   \u001b[0;31m# Read SignatureDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m   \u001b[0mmeta_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_meta_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0msignature_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_signature_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inputs_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mget_meta_graph_def\u001b[0;34m(saved_model_dir, tag_set)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \"\"\"\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m               instructions)\n\u001b[0;32m--> 346\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(sess, tags, export_dir, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m   \"\"\"\n\u001b[0;32m--> 345\u001b[0;31m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSavedModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msaver_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, export_dir)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 121\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /home/mw/models/signal-sleeves-identifier.model.data-00000-of-00001/{saved_model.pbtxt|saved_model.pb}"]}],"execution_count":39}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}
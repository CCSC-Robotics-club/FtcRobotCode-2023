{"cells":[{"cell_type":"code","metadata":{"id":"47A882CDAAA940F2A0378BD64E7AF38C","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport PIL\nimport tensorflow.compat.v1 as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","outputs":[],"execution_count":1},{"cell_type":"code","metadata":{"id":"7F0B9831AF5846E7949E25AA6BF5AAAB","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import os\nvisualMark1 = []\nvisualMark2 = []\nvisualMark3 = []\nfor imageName in os.listdir(r'1'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('1/'+imageName))\n    print(\"loaded asset\", imageName)\nfor imageName in os.listdir(r'2'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('2/'+imageName))\n    print(\"loaded asset\", imageName)\nfor imageName in os.listdir(r'3'):\n    visualMark1.append(tf.keras.preprocessing.image.load_img('3/'+imageName))\n    print(\"loaded asset\", imageName)","outputs":[{"output_type":"stream","name":"stdout","text":"loaded asset WIN_20230328_17_42_00_Pro.jpg\nloaded asset WIN_20230328_17_42_03_Pro.jpg\nloaded asset WIN_20230328_17_42_04_Pro.jpg\nloaded asset WIN_20230328_17_42_07_Pro.jpg\nloaded asset WIN_20230328_17_42_08_Pro.jpg\nloaded asset WIN_20230328_17_42_13_Pro.jpg\nloaded asset WIN_20230328_17_42_19_Pro (2).jpg\nloaded asset WIN_20230328_17_42_19_Pro.jpg\nloaded asset WIN_20230328_17_42_37_Pro.jpg\nloaded asset WIN_20230328_17_42_39_Pro.jpg\nloaded asset WIN_20230328_17_42_47_Pro.jpg\nloaded asset WIN_20230328_17_42_50_Pro.jpg\nloaded asset WIN_20230328_17_42_52_Pro.jpg\nloaded asset WIN_20230328_17_42_55_Pro.jpg\nloaded asset WIN_20230328_17_42_58_Pro.jpg\nloaded asset WIN_20230328_17_43_01_Pro.jpg\nloaded asset WIN_20230328_17_43_03_Pro.jpg\nloaded asset WIN_20230328_17_43_08_Pro.jpg\nloaded asset WIN_20230328_17_44_39_Pro.jpg\nloaded asset WIN_20230328_17_44_42_Pro.jpg\nloaded asset WIN_20230328_17_44_44_Pro.jpg\nloaded asset WIN_20230328_17_44_48_Pro.jpg\nloaded asset WIN_20230328_17_44_51_Pro.jpg\nloaded asset WIN_20230328_17_44_53_Pro.jpg\nloaded asset WIN_20230328_17_44_55_Pro.jpg\nloaded asset WIN_20230328_17_44_57_Pro.jpg\nloaded asset WIN_20230328_17_45_01_Pro.jpg\nloaded asset WIN_20230328_17_45_03_Pro.jpg\nloaded asset WIN_20230328_17_45_06_Pro.jpg\nloaded asset WIN_20230328_17_46_00_Pro.jpg\nloaded asset WIN_20230328_17_46_02_Pro.jpg\nloaded asset WIN_20230328_17_46_06_Pro.jpg\nloaded asset WIN_20230328_17_46_10_Pro.jpg\nloaded asset WIN_20230328_17_46_12_Pro.jpg\nloaded asset WIN_20230328_17_46_13_Pro.jpg\nloaded asset WIN_20230328_17_46_18_Pro.jpg\nloaded asset WIN_20230328_17_43_53_Pro.jpg\nloaded asset WIN_20230328_17_43_54_Pro.jpg\nloaded asset WIN_20230328_17_43_57_Pro.jpg\nloaded asset WIN_20230328_17_44_00_Pro.jpg\nloaded asset WIN_20230328_17_44_01_Pro.jpg\nloaded asset WIN_20230328_17_44_05_Pro.jpg\nloaded asset WIN_20230328_17_44_06_Pro.jpg\nloaded asset WIN_20230328_17_44_10_Pro.jpg\nloaded asset WIN_20230328_17_44_11_Pro.jpg\nloaded asset WIN_20230328_17_44_13_Pro (2).jpg\nloaded asset WIN_20230328_17_44_13_Pro.jpg\nloaded asset WIN_20230328_17_44_17_Pro.jpg\nloaded asset WIN_20230328_17_44_18_Pro.jpg\nloaded asset WIN_20230328_17_44_21_Pro.jpg\nloaded asset WIN_20230328_17_44_22_Pro.jpg\nloaded asset WIN_20230328_17_44_24_Pro.jpg\nloaded asset WIN_20230328_17_44_28_Pro.jpg\nloaded asset WIN_20230328_17_44_30_Pro.jpg\n"}],"execution_count":6},{"cell_type":"code","metadata":{"id":"A6F34E846FF543E2848B699016CF39FA","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"batch_size = 15\nimg_height = 720\nimg_width = 1280\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","outputs":[{"output_type":"error","ename":"AttributeError","evalue":"module 'keras.api._v1.keras.utils' has no attribute 'image_dataset_from_directory'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1297397227.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m train_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m_getattr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \"\"\"\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m# Placeholder for Google-internal contrib error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v1.keras.utils' has no attribute 'image_dataset_from_directory'"]}],"execution_count":8},{"cell_type":"code","metadata":{"id":"3B5784E8644D4D5888E63182535C0EFF","notebookId":"63e72939b5fa5410338747d2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# process and cut the pictures\nfrom PIL import Image\nimport os\n\npath = '/home/mw/'\nfor i in range(1,4):\n    for rawImage in os.listdir(path + str(i) + \"/\"):\n        img = Image.open(path + str(i) + \"/\" + rawImage) # read image from file system\n        img = img.rotate(180) # rotate it 180 degrees\n        box = (400, 360, 760, 720) # the region that the signal sleeves will be seen\n        img = img.crop(box) # cut the region down, into a 360 by 360 image\n        img.show()\n        img.save(path + str(i) + \"/\" + rawImage) # replace the original picture","outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C07050>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lop2paf.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C4AB50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lop920y.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF76B053090>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lopg0xl.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C4AB50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lop8hd5.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C638BD50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loppyqx.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C4AB50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lopg4i3.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C6C9E710>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lopu9sb.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C07050>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lopk0uo.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819FE0D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lopfv3l.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C07050>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loqqasj.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C64033D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loqcnw9.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF76B053090>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loq52qf.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C64033D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loqcit9.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C4AB50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loq88iv.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C64033D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loqi9nq.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C4AB50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loq40pc.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183557D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loqaoa5.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819FE0D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loqqc4o.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183CBE50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loqg8lq.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C6C9E710>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loq2k0p.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183CBE50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loqua9q.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C6C9E710>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lor7pve.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C07050>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lorldqt.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C6C9E710>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lorfzkb.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819FE0D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lorln63.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C6C9E710>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lor75g1.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819FE0D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lor3iix.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C64033D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lorfosg.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819FE0D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lornune.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C07050>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lorfzwk.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF76B053090>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9losudnj.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183CBE50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loswh3t.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF76B053090>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9los3lqh.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183CBE50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9losyzax.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C638BD50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9losnh9.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183CBE50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loss199.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C07050>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9losse86.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183CBE50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9losi3bx.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C64033D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loslstd.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF76B053090>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lotl5hc.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C64033D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lotjaem.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C4AB50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lotkxgo.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C6C9E710>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lot2vpa.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C4AB50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lotfjio.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C07050>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lotwc5j.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C4AB50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lotg6gs.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183557D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lot6wbh.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C64033D0>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9lotbgng.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF76B053090>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loucc4h.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF8183CBE50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9louchav.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819FE0D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9louhjv2.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819C07050>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loukpmh.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF819FE0D50>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loud5e.png\">"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=360x360 at 0x7FF6C6C9E710>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/3B5784E8644D4D5888E63182535C0EFF/rs9loust64.png\">"},"metadata":{}}],"execution_count":2},{"cell_type":"code","metadata":{"id":"A03CDCC7E320498A8BC485A4195F2A79","notebookId":"63e72939b5fa5410338747d2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"","outputs":[],"execution_count":null},{"cell_type":"code","metadata":{"id":"18BDDC139D82410F9777D9FF313738DE","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import os\ndatas = []\nlabels = []\nfpaths = []\nfor imageName in os.listdir(r'/home/mw/1/'):\n    fpath = '/home/mw/1/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/1/'+imageName)) / 255.0\n    label = 0\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\nfor imageName in os.listdir(r'/home/mw/2/'):\n    fpath = '/home/mw/2/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/2/'+imageName)) / 255.0\n    label = 1\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\nfor imageName in os.listdir(r'/home/mw/3/'):\n    fpath = '/home/mw/3/'+imageName\n    data = np.array(PIL.Image.open('/home/mw/3/'+imageName)) / 255.0\n    label = 2\n    fpaths.append(fpath)\n    datas.append(data)\n    labels.append(label)\n    \ndatas = np.array(datas)\nlabels = np.array(labels)\n\nnum_classes = 3","outputs":[],"execution_count":2},{"cell_type":"code","metadata":{"id":"8548BBC73C284CFB82E7AEB1CDAE499E","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"tf.disable_eager_execution()\n# 定义Placeholder，存放输入和标签\ndatas_placeholder = tf.placeholder(\n    tf.float32,\n    [None, 360, 360, 3],\n    name=\"input\"\n    )\nlabels_placeholder = tf.placeholder(\n    tf.int32, \n    [None], \n    name=\"output\"\n)\n\n# 存放DropOut参数的容器，训练时为0.25，测试时为0\ndropout_placeholdr = tf.placeholder(tf.float32)\n\n# 定义卷积层, 20个卷积核, 卷积核大小为5，用Relu激活\nconv0 = tf.layers.conv2d(datas_placeholder, 20, 5, activation=tf.nn.relu)\n# 定义max-pooling层，pooling窗口为2x2，步长为2x2\npool0 = tf.layers.max_pooling2d(conv0, [2, 2], [2, 2])\n\n# 定义卷积层, 40个卷积核, 卷积核大小为4，用Relu激活\nconv1 = tf.layers.conv2d(pool0, 40, 4, activation=tf.nn.relu)\n# 定义max-pooling层，pooling窗口为2x2，步长为2x2\npool1 = tf.layers.max_pooling2d(conv1, [2, 2], [2, 2])\n\n# 将3维特征转换为1维向量\nflatten = tf.layers.flatten(pool1)\n\n# 全连接层，转换为长度为100的特征向量\nfc = tf.layers.dense(flatten, 400, activation=tf.nn.relu)\n\n# 加上DropOut，防止过拟合\ndropout_fc = tf.layers.dropout(fc, dropout_placeholdr)\n\n# 未激活的输出层\nlogits = tf.layers.dense(dropout_fc, num_classes)\n\npredicted_labels = tf.arg_max(logits, 1)\n\n\n# 利用交叉熵定义损失\nlosses = tf.nn.softmax_cross_entropy_with_logits(\n    labels=tf.one_hot(labels_placeholder, num_classes),\n    logits=logits\n)\n# 平均损失\nmean_loss = tf.reduce_mean(losses)\n\n# 定义优化器，指定要优化的损失函数\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-2).minimize(losses)","outputs":[{"output_type":"stream","name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee `tf.nn.softmax_cross_entropy_with_logits_v2`.\n\n"},{"output_type":"stream","name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/legacy_tf_layers/convolutional.py:536: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n  warnings.warn('`tf.layers.conv2d` is deprecated and '\n/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer_v1.py:1676: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n  warnings.warn('`layer.apply` is deprecated and '\n/opt/conda/lib/python3.7/site-packages/keras/legacy_tf_layers/pooling.py:554: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n  warnings.warn('`tf.layers.max_pooling2d` is deprecated and '\n/opt/conda/lib/python3.7/site-packages/keras/legacy_tf_layers/core.py:513: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n  warnings.warn('`tf.layers.flatten` is deprecated and '\n/opt/conda/lib/python3.7/site-packages/keras/legacy_tf_layers/core.py:236: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n  warnings.warn('`tf.layers.dense` is deprecated and '\n/opt/conda/lib/python3.7/site-packages/keras/legacy_tf_layers/core.py:393: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n  warnings.warn('`tf.layers.dropout` is deprecated and '\n"}],"execution_count":3},{"cell_type":"code","metadata":{"id":"5BD164ED92E442AA9791C478114F05C2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"saver = tf.train.Saver()\ntrain = True\nmodel_path = \"/home/mw/models/signal-sleeves-identifier.model\"\nwith tf.Session() as sess:\n    if train:\n        print(\"训练模式\")\n        # 如果是训练，初始化参数\n        sess.run(tf.global_variables_initializer())\n        # 定义输入和Label以填充容器，训练时dropout为0.25\n        train_feed_dict = {\n            datas_placeholder: datas,\n            labels_placeholder: labels,\n            dropout_placeholdr: 0.25\n        }\n        for step in range(2):\n            _, mean_loss_val = sess.run([optimizer, mean_loss], feed_dict=train_feed_dict)\n\n            print(\"step = {}\\tmean loss = {}\".format(step, mean_loss_val))\n        '''tf.compat.v1.saved_model.simple_save( #保存模型\n            sess, model_path, \n            inputs = {\"myInput\": datas_placeholder},\n            outputs = {\"myOutput\" :labels_placeholder}\n        )'''\n        saver.save(sess, model_path)\n        print(\"训练结束，保存模型到{}\".format(model_path))\n    \n    \n    else:\n        print(\"测试模式\")\n        # 如果是测试，载入参数\n        saver.restore(sess, model_path)\n        print(\"从{}载入模型\".format(model_path))\n        # label和名称的对照关系\n        label_name_dict = {\n            0: \"标识1\",\n            1: \"标识2\",\n            2: \"标识3\"\n        }\n        # 定义输入和Label以填充容器，测试时dropout为0\n        test_feed_dict = {\n            datas_placeholder: datas,\n            labels_placeholder: labels,\n            dropout_placeholdr: 0\n        }\n        predicted_labels_val = sess.run(predicted_labels, feed_dict=test_feed_dict)\n        # 真实label与模型预测label\n        for fpath, real_label, predicted_label in zip(fpaths, labels, predicted_labels_val):\n            # 将label id转换为label名\n            real_label_name = label_name_dict[real_label]\n            predicted_label_name = label_name_dict[predicted_label]\n            print(\"{}\\t{} => {}\".format(fpath, real_label_name, predicted_label_name))","outputs":[{"output_type":"stream","name":"stderr","text":"2023-03-29 05:32:03.328563: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-03-29 05:32:03.361294: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 484416000 exceeds 10% of free system memory.\n"},{"output_type":"stream","name":"stdout","text":"训练模式\n"},{"output_type":"stream","name":"stderr","text":"2023-03-29 05:32:03.660322: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 484416000 exceeds 10% of free system memory.\n2023-03-29 05:32:04.054337: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 484416000 exceeds 10% of free system memory.\n2023-03-29 05:32:04.356238: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 484416000 exceeds 10% of free system memory.\n2023-03-29 05:32:05.486507: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 547499520 exceeds 10% of free system memory.\n"},{"output_type":"stream","name":"stdout","text":"step = 0\tmean loss = 1.1034849882125854\nstep = 1\tmean loss = 588.12744140625\n训练结束，保存模型到/home/mw/models/signal-sleeves-identifier.model\n"}],"execution_count":4},{"cell_type":"code","metadata":{"id":"0B7E502647AB42D38B001EFED1D88812","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"notebookId":"63e72939b5fa5410338747d2","trusted":true},"source":"import tensorflow as tf\nfrom tensorflow.python.platform import gfile\n\n'''# first, convert the model into pbtxt file\nwith gfile.FastGFile(model_path + \"/saved_model.pb\") as f:\n  graph_def = tf.compat.v1.GraphDef()\n  graph_def.ParseFromString(f.read())\n  tf.import_graph_def(graph_def, name='')\n  tf.train.write_graph(graph_def, \"./\", \"signal_sleeves.pbtxt\", as_text=True)\n'''\n\n# Convert the model\nconverter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(\"/home/mw/models/\") # path to the SavedModel directory\n\ntflite_model = converter.convert()\n\n# Save the model.\nwith open('model.tflite', 'wb') as f:\n  f.write(tflite_model)","outputs":[{"output_type":"stream","name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_saved_model.py:63: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"},{"output_type":"error","ename":"OSError","evalue":"SavedModel file does not exist at: /home/mw/models//{saved_model.pbtxt|saved_model.pb}","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/623159061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Convert the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/mw/models/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# path to the SavedModel directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_saved_model\u001b[0;34m(cls, saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[1;32m   2265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m     saved_model_converter = TFLiteSavedModelConverter(saved_model_dir, tag_set,\n\u001b[0;32m-> 2267\u001b[0;31m                                                       [signature_key])\n\u001b[0m\u001b[1;32m   2268\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msaved_model_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_converter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, saved_model_dir, saved_model_tags, saved_model_exported_names, experimental_debug_info_func)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     result = _freeze_saved_model(self.saved_model_dir, None, None, None,\n\u001b[0;32m-> 1744\u001b[0;31m                                  self._saved_model_tags, signature_key)\n\u001b[0m\u001b[1;32m   1745\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mreport_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Re-throws the exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_phase.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mConverterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconverter_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mfreeze_saved_model\u001b[0;34m(saved_model_dir, input_arrays, input_shapes, output_arrays, tag_set, signature_key)\u001b[0m\n\u001b[1;32m    189\u001b[0m   \"\"\"\n\u001b[1;32m    190\u001b[0m   \u001b[0;31m# Read SignatureDef.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m   \u001b[0mmeta_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_meta_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0msignature_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_signature_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m   \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inputs_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/convert_saved_model.py\u001b[0m in \u001b[0;36mget_meta_graph_def\u001b[0;34m(saved_model_dir, tag_set)\u001b[0m\n\u001b[1;32m     61\u001b[0m   \"\"\"\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m               instructions)\n\u001b[0;32m--> 346\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(sess, tags, export_dir, import_scope, **saver_kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m   \"\"\"\n\u001b[0;32m--> 345\u001b[0;31m   \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSavedModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msaver_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, export_dir)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_export_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_model_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 121\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /home/mw/models//{saved_model.pbtxt|saved_model.pb}"]}],"execution_count":6},{"cell_type":"code","metadata":{"id":"066B277589E144488A65C852FAB8A773","notebookId":"63e72939b5fa5410338747d2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"os.system(\"tflite_convert --saved_model_dir=./signal-sleeves-identifier.pb.data-00000-of-00001 --output_file=./signal_sleeves.tflite\")","outputs":[{"output_type":"stream","name":"stderr","text":"Traceback (most recent call last):\n  File \"/opt/conda/bin/tflite_convert\", line 8, in <module>\n    sys.exit(main())\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 697, in main\n    app.run(main=run_main, argv=sys.argv[:1])\n  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 312, in run\n    _run_main(main, args)\n  File \"/opt/conda/lib/python3.7/site-packages/absl/app.py\", line 258, in _run_main\n    sys.exit(main(argv))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 680, in run_main\n    _convert_tf2_model(tflite_flags)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/tflite_convert.py\", line 284, in _convert_tf2_model\n    tags=_parse_set(flags.saved_model_tag_set))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 1348, in from_saved_model\n    saved_model = _load(saved_model_dir, tags)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 864, in load\n    result = load_internal(export_dir, tags, options)[\"root\"]\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 878, in load_internal\n    loader_impl.parse_saved_model_with_debug_info(export_dir))\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 60, in parse_saved_model_with_debug_info\n    saved_model = _parse_saved_model(export_dir)\n  File \"/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 121, in parse_saved_model\n    constants.SAVED_MODEL_FILENAME_PB))\nOSError: SavedModel file does not exist at: ./signal-sleeves-identifier.pb.data-00000-of-00001/{saved_model.pbtxt|saved_model.pb}\n"},{"output_type":"execute_result","data":{"text/plain":"256"},"metadata":{},"execution_count":9}],"execution_count":9},{"cell_type":"code","metadata":{"id":"24FF3DDAE37046808239C9CAC0D10FC5","notebookId":"63e72939b5fa5410338747d2","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"source":"# 以下为格式转换\nimport tensorflow as tf\n# 首先，获取节点名称\nsaver = tf.compat.v1.train.import_meta_graph(model_path + '.meta', clear_devices=True)\ngraph = tf.compat.v1.get_default_graph()\ninput_graph_def = graph.as_graph_def()\nwith tf.compat.v1.Session() as sess:\n    for n in tf.compat.v1.get_default_graph().as_graph_def().node:\n        if \"input\" in n.name:\n            print(n.name)\n\n\n# 冻结为固定参数模型\nsaver = tf.compat.v1.train.import_meta_graph(model_path + \".meta\")\ngraph = tf.compat.v1.get_default_graph()\ninput_graph_def = graph.as_graph_def()\nwith tf.compat.v1.Session() as sess:\n    saver.restore(sess, model_path)\n    output_graph_def = tf.compat.v1.graph_util.convert_variables_to_constants(\n        sess = sess,\n        input_graph_def = input_graph_def,\n        output_node_names = [\"output\"]\n    )\n    with tf.compat.v1.gfile.GFile(\"/home/mw/frozen.pb\", \"wb\") as f:\n        f.write(output_graph_def.SerializeToString())\n\n# 将冻结完毕的模型转为tflite文件\nconvert = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\n    \"/home/mw/frozen.pb\",\n    input_arrays = [\"input\"], \n    output_arrays = [\"output\"],\n    input_shapes={\"input\": [None, 360, 360 ,3]}\n)\nconvert.post_training_quantize = True\ntflite_model = convert.convert()\nopen(\"/home/mw/siganl_sleeves.tflite\", \"wb\").write(tflite_model)","outputs":[{"output_type":"stream","name":"stdout","text":"input\nsave/filename/input\ninput_1\nsave/filename/input_1\ninput_2\nsave/filename/input_2\ninput_3\nsave/filename/input_3\ninput_4\nsave/filename/input_4\ninput_5\nsave/filename/input_5\ninput_6\nsave/filename/input_6\ninput_7\nsave/filename/input_7\ninput_8\nsave/filename/input_8\ninput_9\nsave/filename/input_9\ninput_10\nsave/filename/input_10\ninput_11\nsave/filename/input_11\ninput_12\nsave/filename/input_12\nINFO:tensorflow:Restoring parameters from /home/mw/models/signal-sleeves-identifier.model\n"},{"output_type":"error","ename":"ValueError","evalue":"Invalid tensors 'input' were found.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_829/3193042995.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0minput_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moutput_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0minput_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_quantize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mfrom_frozen_graph\u001b[0;34m(cls, graph_def_file, input_arrays, output_arrays, input_shapes)\u001b[0m\n\u001b[1;32m   2207\u001b[0m           \u001b[0;31m# Get input and output tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m           input_tensors = _get_tensors_from_tensor_names(\n\u001b[0;32m-> 2209\u001b[0;31m               sess.graph, input_arrays)\n\u001b[0m\u001b[1;32m   2210\u001b[0m           output_tensors = _get_tensors_from_tensor_names(\n\u001b[1;32m   2211\u001b[0m               sess.graph, output_arrays)\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/lite/python/util.py\u001b[0m in \u001b[0;36mget_tensors_from_tensor_names\u001b[0;34m(graph, tensor_names)\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minvalid_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     raise ValueError(\"Invalid tensors '{}' were found.\".format(\n\u001b[0;32m--> 161\u001b[0;31m         \",\".join(invalid_tensors)))\n\u001b[0m\u001b[1;32m    162\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid tensors 'input' were found."]}],"execution_count":15}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":5}